{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from ipywidgets import interact\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [14, 10]\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "def getRandomColorMap(num_colors, bg_color=1):\n",
    "    colors = np.random.rand(num_colors, 3) * 0.75\n",
    "    colors[0, :] = bg_color\n",
    "    colors = tuple(map(tuple, colors))\n",
    "\n",
    "    labelColorMap = LinearSegmentedColormap.from_list('labelColorMap', colors, N=num_colors)\n",
    "\n",
    "    return labelColorMap\n",
    "\n",
    "def multiplot(lines, rows, images, cmap, title, save=False):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    for i in np.arange(lines*rows):\n",
    "        \n",
    "        plt.subplot(lines, rows, i+1)\n",
    "        plt.imshow(images[i], vmax=255, cmap=cmap[i])\n",
    "        plt.title(title[i])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig('img.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the image and convert it in grayscale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('Images/baboon.png')\n",
    "\n",
    "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "multiplot(1, 2, (rgb_image, gray_image), (cm.viridis, cm.gray), ('Original image', 'Gray image')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most basic linear filtering is a moving average of the image.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_filter(kx, ky):\n",
    "    kernel = np.ones((ky, kx)) / (kx*ky)\n",
    "    avg_image = cv2.filter2D(gray_image, -1, kernel)\n",
    "    \n",
    "    multiplot(1, 2, (gray_image, avg_image), (cm.gray, cm.gray), ('Gray image', 'Average filtered image'))\n",
    "    \n",
    "interact(average_filter, kx=(1, 11, 2), ky=(1, 11, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the difference between average filtering and uniform blurring?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blurring_filter(kx, ky):\n",
    "    kernel = (ky, kx)\n",
    "    blur_image = cv2.blur(gray_image, kernel)\n",
    "    \n",
    "    multiplot(1, 2, (gray_image, blur_image), (cm.gray, cm.gray), ('Gray image', 'Blurred image'))\n",
    "    \n",
    "interact(blurring_filter, kx=(1, 11, 2), ky=(1, 11, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_image = cv2.filter2D(gray_image, -1, np.ones((3, 3)) / (3*3))\n",
    "blur_image = cv2.blur(gray_image, (3, 3))\n",
    "box_image = cv2.boxFilter(gray_image, -1, (3, 3), normalize=True)\n",
    "\n",
    "(avg_image.flatten() == blur_image.flatten()).sum() / avg_image.size, (avg_image.flatten() == box_image.flatten()).sum() / avg_image.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the difference between uniform and gaussian blurring?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_filter(kx, ky):\n",
    "    kernel = (ky, kx)\n",
    "    gauss_image = cv2.GaussianBlur(gray_image, kernel, sigmaX=0)     \n",
    "    \n",
    "    multiplot(1, 2, (gray_image, gauss_image), (cm.gray, cm.gray), ('Gray image', 'Gaussian blurred image'))\n",
    "    \n",
    "interact(gaussian_filter, kx=(1, 11, 2), ky=(1, 11, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obtain a high pass filtered image by applying a low pas filter and then taking the complementary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_filter(kx, ky):\n",
    "    kernel = (ky, kx)\n",
    "    gauss_image = cv2.GaussianBlur(gray_image, kernel, 3)\n",
    "    \n",
    "    hp = gray_image - gauss_image\n",
    "    \n",
    "    multiplot(1, 2, (gray_image, hp), (cm.gray, cm.gray), ('Gray image', 'HP filter image'))\n",
    "    \n",
    "interact(hp_filter, kx=(1, 21, 2), ky=(1, 21, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute and display the histogram of a grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameraman_gray = cv2.imread('Images/cameraman.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "plt.imshow(cameraman_gray, cmap=cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_np, bins = np.histogram(cameraman_gray.ravel(), 256, [0,256])\n",
    "\n",
    "hist_cv = cv2.calcHist( [cameraman_gray], [0], None, [256], [0,256])\n",
    "\n",
    "plt.hist(cameraman_gray.ravel(), bins=256, range=(0,255))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameraman_threshold = cameraman_gray > 100\n",
    "\n",
    "plt.imshow(cameraman_threshold, cmap=cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thresholding with OpenCV\n",
    "Determine the v1 and v2 values for the following threshold types:  \n",
    "cv.THRESH_BINARY\n",
    "$$\\text{th_image}(x,y)=\\left\\{\n",
    "                \\begin{array}{ll}\n",
    "                  \\texttt{v1} & \\text{if img$(x,y)$ > thresh}\\\\\n",
    "                  \\texttt{v2} & \\text{otherwise}\n",
    "                \\end{array}\n",
    "              \\right.\n",
    "$$\n",
    "\n",
    "cv.THRESH_BINARY_INV\n",
    "$$\\text{th_image}(x,y)=\\left\\{\n",
    "                \\begin{array}{ll}\n",
    "                  \\texttt{v1} & \\text{if img$(x,y)$ > thresh}\\\\\n",
    "                  \\texttt{v2} & \\text{otherwise}\n",
    "                \\end{array}\n",
    "              \\right.\n",
    "$$\n",
    "\n",
    "cv.THRESH_TRUNC\n",
    "$$\\text{th_image}(x,y)=\\left\\{\n",
    "                \\begin{array}{ll}\n",
    "                  \\texttt{v1} & \\text{if img$(x,y)$ > thresh}\\\\\n",
    "                  \\texttt{v2} & \\text{otherwise}\n",
    "                \\end{array}\n",
    "              \\right.\n",
    "$$\n",
    "\n",
    "cv.THRESH_TO_ZERO\n",
    "$$\\text{th_image}(x,y)=\\left\\{\n",
    "                \\begin{array}{ll}\n",
    "                  \\texttt{v1} & \\text{if img$(x,y)$ > thresh}\\\\\n",
    "                  \\texttt{v2} & \\text{otherwise}\n",
    "                \\end{array}\n",
    "              \\right.\n",
    "$$\n",
    "\n",
    "cv.THRESH_TO_ZERO_INV\n",
    "$$\\text{th_image}(x,y)=\\left\\{\n",
    "                \\begin{array}{ll}\n",
    "                  \\texttt{v1} & \\text{if img$(x,y)$ > thresh}\\\\\n",
    "                  \\texttt{v2} & \\text{otherwise}\n",
    "                \\end{array}\n",
    "              \\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = cv2.imread('Images/gradient.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "value = 150\n",
    "\n",
    "ret, thresh1 = cv2.threshold(grad, value, 255, cv2.THRESH_BINARY)\n",
    "ret, thresh2 = cv2.threshold(grad, value, 255, cv2.THRESH_BINARY_INV)\n",
    "ret, thresh3 = cv2.threshold(grad, value, 255, cv2.THRESH_TRUNC)\n",
    "ret, thresh4 = cv2.threshold(grad, value, 255, cv2.THRESH_TOZERO)\n",
    "ret, thresh5 = cv2.threshold(grad, value, 255, cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "multiplot(2, 3,\n",
    "          (grad, thresh1, thresh2, thresh3, thresh4, thresh5),\n",
    "          (cm.gray, cm.gray, cm.gray, cm.gray, cm.gray, cm.gray),\n",
    "          ('Original Image', 'THRESH_BINARY', 'THRESH_BINARY_INV',\n",
    "           'THRESH_TRUNC', 'THRESH_TOZERO', 'THRESH_TOZERO_INV'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = 127\n",
    "\n",
    "ret, thresh1 = cv2.threshold(cameraman_gray, value, 255, cv2.THRESH_BINARY)\n",
    "ret, thresh2 = cv2.threshold(cameraman_gray, value, 255, cv2.THRESH_BINARY_INV)\n",
    "ret, thresh3 = cv2.threshold(cameraman_gray, value, 255, cv2.THRESH_TRUNC)\n",
    "ret, thresh4 = cv2.threshold(cameraman_gray, value, 255, cv2.THRESH_TOZERO)\n",
    "ret, thresh5 = cv2.threshold(cameraman_gray, value, 255, cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "multiplot(2, 3,\n",
    "         (cameraman_gray, thresh1, thresh2, thresh3, thresh4, thresh5),\n",
    "         (cm.gray, cm.gray, cm.gray, cm.gray, cm.gray, cm.gray),\n",
    "         ('Original Image', 'THRESH_BINARY', 'THRESH_BINARY_INV',\n",
    "          'THRESH_TRUNC', 'THRESH_TOZERO', 'THRESH_TOZERO_INV'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous examples, we had to chose the threshold value. We can use Otsu's algorithm to determine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rice = cv2.imread('Images/rice.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "plt.hist(rice.ravel(), bins=256, range=(0,255))\n",
    "plt.show()\n",
    "\n",
    "ret, thresh1 = cv2.threshold(rice, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "ret, otsu = cv2.threshold(rice, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "multiplot(1, 3,\n",
    "         (rice, thresh1, otsu),\n",
    "         (cm.gray, cm.gray, cm.gray),\n",
    "         ('Original Image', 'THRESH_BINARY', 'THRESH_BINARY + OTSU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can fine-tune the result by applying this algorithm on the different parts of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "h = np.linspace(0, rice.shape[0], n+1).astype('int')\n",
    "out = []\n",
    "for i in range(n):\n",
    "    ret, th = cv2.threshold(rice[h[i]: h[i+1], :], 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    out.append(th)\n",
    "\n",
    "out = np.concatenate(out, axis=0)\n",
    "\n",
    "multiplot(1, 3,\n",
    "         (rice, otsu, out),\n",
    "         (cm.gray, cm.gray, cm.gray),\n",
    "         ('Original Image', 'OTSU', 'OTSU BY PARTS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def otsu_parts(img, n, direction):\n",
    "    \n",
    "    out = []\n",
    "    \n",
    "    if direction == 'horizontal':\n",
    "        l = img.shape[0]\n",
    "        h = np.linspace(0, l, n+1).astype('int')\n",
    "        \n",
    "        for i in range(n):\n",
    "            ret, th = cv2.threshold(img[h[i]: h[i+1], :], 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            out.append(th)\n",
    "    else:\n",
    "        l = img.shape[1]\n",
    "        h = np.linspace(0, l, n+1).astype('int')\n",
    "        \n",
    "        for i in range(n):\n",
    "            ret, th = cv2.threshold(img[:, h[i]: h[i+1]], 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            out.append(th)\n",
    "    \n",
    "    \n",
    "    return np.concatenate(out, axis=0)\n",
    "\n",
    "light_gradient = np.arange(start=132, stop=-133, step=-1) / 3\n",
    "non_uniform_lightning = (np.reshape(light_gradient, (265, 1))) * np.ones((1, 250), dtype=int)\n",
    "\n",
    "img_nu = np.clip(rice+non_uniform_lightning, 0, 255).astype(np.uint8)\n",
    "\n",
    "plt.hist(img_nu.ravel(), bins=256, range=(0,255))\n",
    "\n",
    "ret, otsu = cv2.threshold(img_nu, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "otsu_p = otsu_parts(img_nu, 5, 'horizontal')\n",
    "\n",
    "multiplot(2, 2,\n",
    "         (rice, non_uniform_lightning, otsu, otsu_p),\n",
    "         (cm.gray, cm.gray, cm.gray, cm.gray),\n",
    "         ('Original Image', 'Non-uniform lightning', 'OTSU', 'OTSU BY PARTS'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = cv2.imread('Images/pattern_inspection2.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "gaussian_noise = np.zeros_like(pattern, dtype=float)\n",
    "mean = 0.\n",
    "std = 10.\n",
    "cv2.randn(gaussian_noise, mean, std)\n",
    "\n",
    "pattern_noisy = np.clip(pattern+gaussian_noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "multiplot(1, 2,\n",
    "         (pattern, pattern_noisy),\n",
    "         (cm.gray, cm.gray),\n",
    "         ('Original image', 'Gaussian noise'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salt and pepper noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_pepper_noise = np.zeros_like(cameraman_gray)\n",
    "cv2.randu(salt_pepper_noise, 0, 255)\n",
    "cameraman_noisy = np.where(salt_pepper_noise < 10, 0, np.where(salt_pepper_noise > 240, 255, cameraman_gray))\n",
    "\n",
    "multiplot(1, 2,\n",
    "         (cameraman_gray, cameraman_noisy),\n",
    "         (cm.gray, cm.gray),\n",
    "         ('Original image', 'Salt and pepper noise'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameraman_noisy_uniform_blur = cv2.blur(cameraman_noisy, (7, 7))\n",
    "cameraman_noisy_gaussian_blur = cv2.GaussianBlur(cameraman_noisy, (7, 7), 0)\n",
    "cameraman_noisy_bilateral = cv2.bilateralFilter(cameraman_noisy, -1, 25, 11)\n",
    "\n",
    "multiplot(2, 2,\n",
    "         (cameraman_gray, cameraman_noisy_uniform_blur, cameraman_noisy_gaussian_blur, cameraman_noisy_bilateral),\n",
    "         (cm.gray, cm.gray, cm.gray, cm.gray),\n",
    "         ('Original image', 'Uniform blur', 'Gaussian blur', 'Bilateral filtering'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_pepper_noise = np.zeros_like(cameraman_gray)\n",
    "cv2.randu(salt_pepper_noise, 0, 255)\n",
    "cameraman_noisy = np.where(salt_pepper_noise < 30, 0, np.where(salt_pepper_noise > 200, 255, cameraman_gray))\n",
    "\n",
    "cameraman_noisy_median = cv2.medianBlur(cameraman_noisy, 5)\n",
    "\n",
    "multiplot(1, 3,\n",
    "         (cameraman_gray, cameraman_noisy, cameraman_noisy_median),\n",
    "         (cm.gray, cm.gray, cm.gray),\n",
    "         ('Salt and pepper noise', 'Noisy image', 'Median blur'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_uniform_lightning_like(img, weight):\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    \n",
    "    steps_y = np.arange( start=0.0, stop=1.0, step=1.0/height)\n",
    "    light_gradient_y = np.cos( ( 2.0 * ( steps_y * steps_y - steps_y) + 1.0)* np.pi)[:,np.newaxis]\n",
    "\n",
    "    steps_x = np.arange( start=0.0, stop=1.0, step=1.0/width)\n",
    "    light_gradient_x = np.cos( steps_x * np.pi)[np.newaxis,:]\n",
    "\n",
    "    return ( weight * light_gradient_y * light_gradient_x)\n",
    "\n",
    "nul = non_uniform_lightning_like(rice, 50)\n",
    "rice_nul = np.clip(rice + nul, 0, 255).astype(np.uint8)\n",
    "\n",
    "multiplot(1, 3,\n",
    "         (rice, nul, rice_nul),\n",
    "         (cm.gray, cm.gray, cm.gray),\n",
    "         ('Original Image', 'Non Uniform Lightning', 'Image + Non Uniform Lightning'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 19\n",
    "kernel = np.ones((k, k))\n",
    "\n",
    "erd = cv2.erode(rice_nul, kernel, iterations=1)\n",
    "dlt = cv2.dilate(rice_nul, kernel, iterations=1)\n",
    "\n",
    "multiplot(1, 2,\n",
    "         (erd, dlt),\n",
    "         (cm.gray, cm.gray),\n",
    "         ('Erosion', 'Dilation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_erd = cv2.GaussianBlur(erd, (k, k), 0)\n",
    "gaussian_dlt = cv2.GaussianBlur(dlt, (k, k), 0)\n",
    "\n",
    "multiplot(1, 2,\n",
    "         (gaussian_erd, gaussian_dlt),\n",
    "         (cm.gray, cm.gray),\n",
    "         ('Background', 'Foreground'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_normalize_image(img, k):\n",
    "    kernel = np.ones((k, k))\n",
    "    \n",
    "    erd = cv2.erode(img, kernel, iterations=1)\n",
    "    dlt = cv2.dilate(img, kernel, iterations=1)\n",
    "    \n",
    "    gaussian_erd = cv2.GaussianBlur(erd, (k, k), 0)\n",
    "    gaussian_dlt = cv2.GaussianBlur(dlt, (k, k), 0)\n",
    "    \n",
    "    norm_img = (img - gaussian_erd)/(gaussian_dlt - gaussian_erd + 1) * 255\n",
    "    \n",
    "    return np.clip(norm_img, 0, 255).astype(np.uint8)\n",
    "\n",
    "rice_nul_norm = local_normalize_image(rice_nul, 19)\n",
    "\n",
    "ret, thresh1 = cv2.threshold(rice_nul, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "ret, thresh2 = cv2.threshold(rice_nul_norm, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "multiplot(2, 2,\n",
    "         (rice_nul, rice_nul_norm, thresh1, thresh2),\n",
    "         (cm.gray, cm.gray, cm.gray, cm.gray),\n",
    "         ('Image + Non Uniform Lightning', 'Uniformized Image', 'OTSU', 'OTSU + uniformized'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
